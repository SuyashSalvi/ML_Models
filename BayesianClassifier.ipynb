{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ssMWrKhNakJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Classifier"
      ],
      "metadata": {
        "id": "8fINWmGc_wOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf(mean, sd, x):\n",
        "    # Calculate the likelihood using the normal distribution formula\n",
        "    expo = np.multiply(np.square(np.divide(np.subtract(x, mean), sd)),-0.5)\n",
        "    k = np.sqrt(np.multiply(np.multiply(np.square(sd),np.pi),2.0))\n",
        "    likelihood = np.divide(np.exp(expo),k)\n",
        "    return likelihood\n",
        "\n",
        "def binary_bc_training(dataset, dim):\n",
        "    # Initialize variables to store sums and counts for positive and negative samples\n",
        "    sum_p = np.zeros(dim)\n",
        "    sum_n = np.zeros(dim)\n",
        "    sqr_sum_p = np.zeros(dim)\n",
        "    sqr_sum_n = np.zeros(dim)\n",
        "    count_p = 0\n",
        "    count_n = 0\n",
        "\n",
        "    # Iterate over each sample in the dataset\n",
        "    for each in range(len(dataset)):\n",
        "        # Extract the feature values (x_train) and class label (last element)\n",
        "        x_train = dataset[each][0:dim]\n",
        "        y_train = dataset[each][dim]\n",
        "\n",
        "        # If the class label is positive, update the corresponding sums and counts\n",
        "        if y_train > 0:\n",
        "            sum_p += x_train\n",
        "            sqr_sum_p += x_train**2\n",
        "            count_p += 1\n",
        "        # If the class label is negative, update the corresponding sums and counts\n",
        "        else:\n",
        "            sum_n += x_train\n",
        "            sqr_sum_n += x_train**2\n",
        "            count_n += 1\n",
        "\n",
        "    # Calculate the mean, variance, and standard deviation for positive samples\n",
        "    mean_p = sum_p / count_p\n",
        "    var_p = (sqr_sum_p / count_p) - (mean_p**2)\n",
        "    sd_p = np.sqrt(var_p)\n",
        "\n",
        "    # Calculate the mean, variance, and standard deviation for negative samples\n",
        "    mean_n = sum_n / count_n\n",
        "    var_n = (sqr_sum_n / count_n) - (mean_n**2)\n",
        "    sd_n = np.sqrt(var_n)\n",
        "\n",
        "    # Return the mean and standard deviation for both classes\n",
        "    return mean_p, sd_p, mean_n, sd_n\n",
        "\n",
        "\n",
        "def binary_bc_inferencing(mean_p, sd_p, mean_n, sd_n, x, dim, p_pos, p_neg):\n",
        "    # Calculate the likelihood of the new data point being in the positive and negative classes\n",
        "    pos_given_x = np.prod(pdf(mean_p, sd_p, x))\n",
        "    neg_given_x = np.prod(pdf(mean_n, sd_n, x))\n",
        "\n",
        "    # Compare the product of likelihoods for each class\n",
        "    if pos_given_x * p_pos > neg_given_x * p_neg:\n",
        "        return 1  # Positive class\n",
        "    else:\n",
        "        return -1  # Negative class\n"
      ],
      "metadata": {
        "id": "ktiwY7zk_umX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dimension of the data\n",
        "dim = 2\n",
        "\n",
        "# Define the number of samples to generate\n",
        "target_num_samples = 40  # This is the number of positive samples in the testing set\n",
        "\n",
        "# Try 10 times\n",
        "for r in range(30):\n",
        "\n",
        "    # Initialize the dataset\n",
        "    Sn = []  # List to store negative samples\n",
        "    Sp = []  # List to store positive samples\n",
        "    num_n = 0  # Counter for negative samples\n",
        "    num_p = 0  # Counter for positive samples\n",
        "    true_positive = 0  # Counter for true positive samples\n",
        "    true_negative = 0  # Counter for true negative samples\n",
        "    false_positive = 0  # Counter for false positive samples\n",
        "    false_negative = 0  # Counter for false negative samples\n",
        "\n",
        "    # Generate samples until the target number is reached for both positive and negative samples\n",
        "    while num_p < target_num_samples * 2 or num_n < target_num_samples * 2:\n",
        "        # Generate a random vector within the range [-5, 5] with dimension (dim+1)\n",
        "        random_sample = np.random.uniform(-5, 5, (dim + 1))\n",
        "        # Set the last dimension to 0 temporarily\n",
        "        random_sample[dim] = 0\n",
        "        # Compute the sum of the vector components\n",
        "        sum_vector = np.sum(random_sample)\n",
        "        # If the sum is positive, append the sample to Sp\n",
        "        if sum_vector > 0:\n",
        "            if num_p < target_num_samples * 2:\n",
        "                random_sample[dim] = 1\n",
        "                Sp.append(random_sample)\n",
        "                num_p += 1\n",
        "        elif num_n < target_num_samples * 2:\n",
        "            random_sample[dim] = -1\n",
        "            Sn.append(random_sample)\n",
        "            num_n += 1\n",
        "\n",
        "    # Split the dataset into training (Sp, Sn) and testing (Tp, Tn)\n",
        "    # The last target_num_samples samples from Sn and Sp are used for testing.\n",
        "    Tp = Sp[target_num_samples:]\n",
        "    Tn = Sn[target_num_samples:]\n",
        "\n",
        "    # The first target_num_samples samples from Sn and Sp are used for training.\n",
        "    Sp = Sp[:target_num_samples]\n",
        "    Sn = Sn[:target_num_samples]\n",
        "\n",
        "    # Combine positive and negative samples to create the dataset\n",
        "    dataset = Sn + Sp\n",
        "\n",
        "    # Calculate the Gaussian distribution based on training data\n",
        "    mean_p, sd_p, mean_n, sd_n = binary_bc_training(dataset, dim)\n",
        "\n",
        "    # Combine positive and negative samples to create the testing dataset\n",
        "    testing_dataset = Tp + Tn\n",
        "\n",
        "    # Initialize counters for evaluation metrics\n",
        "    true_positive = 0\n",
        "    true_negative = 0\n",
        "    false_positive = 0\n",
        "    false_negative = 0\n",
        "\n",
        "    # Loop through the testing_dataset\n",
        "    for each in range(len(testing_dataset)):\n",
        "        # Make a prediction using the binary_bc_inferencing function with the testing sample\n",
        "        prediction = binary_bc_inferencing(mean_p, sd_p, mean_n, sd_n, testing_dataset[each][0:dim], dim, 0.5, 0.5)  # Prior probability = 0.5 for both classes\n",
        "\n",
        "        # Increment the appropriate counters based on whether the inference is true positive, true negative, false positive, or false negative\n",
        "        if testing_dataset[each][dim] == 1:\n",
        "            if prediction == 1:\n",
        "                true_positive += 1\n",
        "            else:\n",
        "                false_negative += 1\n",
        "        else:\n",
        "            if prediction == -1:\n",
        "                true_negative += 1\n",
        "            else:\n",
        "                false_positive += 1\n",
        "\n",
        "    # Calculate precision\n",
        "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
        "\n",
        "    # Calculate recall\n",
        "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    # Print the result\n",
        "    print(\"Case\",r+1,\"Precision:\", precision, \"Recall:\", recall, \"F1 Score:\", f1score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br5kxr6_iKm2",
        "outputId": "5b6132c9-53fa-4db6-ed77-cb70971e9331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case 1 Precision: 0.975609756097561 Recall: 1.0 F1 Score: 0.9876543209876543\n",
            "Case 2 Precision: 1.0 Recall: 0.95 F1 Score: 0.9743589743589743\n",
            "Case 3 Precision: 0.9743589743589743 Recall: 0.95 F1 Score: 0.9620253164556962\n",
            "Case 4 Precision: 0.85 Recall: 0.85 F1 Score: 0.85\n",
            "Case 5 Precision: 1.0 Recall: 0.925 F1 Score: 0.961038961038961\n",
            "Case 6 Precision: 0.975 Recall: 0.975 F1 Score: 0.975\n",
            "Case 7 Precision: 0.8974358974358975 Recall: 0.875 F1 Score: 0.8860759493670887\n",
            "Case 8 Precision: 0.975609756097561 Recall: 1.0 F1 Score: 0.9876543209876543\n",
            "Case 9 Precision: 1.0 Recall: 0.95 F1 Score: 0.9743589743589743\n",
            "Case 10 Precision: 0.8372093023255814 Recall: 0.9 F1 Score: 0.8674698795180723\n",
            "Case 11 Precision: 0.9210526315789473 Recall: 0.875 F1 Score: 0.8974358974358975\n",
            "Case 12 Precision: 0.9090909090909091 Recall: 1.0 F1 Score: 0.9523809523809523\n",
            "Case 13 Precision: 1.0 Recall: 0.775 F1 Score: 0.8732394366197184\n",
            "Case 14 Precision: 1.0 Recall: 0.95 F1 Score: 0.9743589743589743\n",
            "Case 15 Precision: 0.975609756097561 Recall: 1.0 F1 Score: 0.9876543209876543\n",
            "Case 16 Precision: 1.0 Recall: 0.925 F1 Score: 0.961038961038961\n",
            "Case 17 Precision: 0.972972972972973 Recall: 0.9 F1 Score: 0.935064935064935\n",
            "Case 18 Precision: 1.0 Recall: 0.95 F1 Score: 0.9743589743589743\n",
            "Case 19 Precision: 0.8695652173913043 Recall: 1.0 F1 Score: 0.9302325581395349\n",
            "Case 20 Precision: 0.975609756097561 Recall: 1.0 F1 Score: 0.9876543209876543\n",
            "Case 21 Precision: 0.8780487804878049 Recall: 0.9 F1 Score: 0.888888888888889\n",
            "Case 22 Precision: 0.9047619047619048 Recall: 0.95 F1 Score: 0.9268292682926829\n",
            "Case 23 Precision: 0.9302325581395349 Recall: 1.0 F1 Score: 0.963855421686747\n",
            "Case 24 Precision: 0.9512195121951219 Recall: 0.975 F1 Score: 0.9629629629629629\n",
            "Case 25 Precision: 0.8636363636363636 Recall: 0.95 F1 Score: 0.9047619047619048\n",
            "Case 26 Precision: 0.8888888888888888 Recall: 0.8 F1 Score: 0.8421052631578948\n",
            "Case 27 Precision: 0.875 Recall: 0.875 F1 Score: 0.875\n",
            "Case 28 Precision: 0.8974358974358975 Recall: 0.875 F1 Score: 0.8860759493670887\n",
            "Case 29 Precision: 1.0 Recall: 0.95 F1 Score: 0.9743589743589743\n",
            "Case 30 Precision: 1.0 Recall: 0.825 F1 Score: 0.9041095890410958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFsBMaYMoJqj",
        "outputId": "cc5ae80c-fe7f-4375-b378-9a8d38213fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case 1 Precision: 0.9731182795698925 Recall: 0.905 F1 Score: 0.9378238341968912\n",
            "Case 2 Precision: 0.9038461538461539 Recall: 0.94 F1 Score: 0.9215686274509804\n",
            "Case 3 Precision: 0.8947368421052632 Recall: 0.935 F1 Score: 0.9144254278728606\n",
            "Case 4 Precision: 0.953125 Recall: 0.915 F1 Score: 0.9336734693877552\n",
            "Case 5 Precision: 0.9459459459459459 Recall: 0.875 F1 Score: 0.9090909090909091\n",
            "Case 6 Precision: 0.9211822660098522 Recall: 0.935 F1 Score: 0.9280397022332506\n",
            "Case 7 Precision: 0.905 Recall: 0.905 F1 Score: 0.905\n",
            "Case 8 Precision: 0.9642857142857143 Recall: 0.945 F1 Score: 0.9545454545454546\n",
            "Case 9 Precision: 0.9073170731707317 Recall: 0.93 F1 Score: 0.9185185185185186\n",
            "Case 10 Precision: 0.9090909090909091 Recall: 0.95 F1 Score: 0.9290953545232273\n",
            "Case 11 Precision: 0.915 Recall: 0.915 F1 Score: 0.915\n",
            "Case 12 Precision: 0.9411764705882353 Recall: 0.88 F1 Score: 0.9095607235142118\n",
            "Case 13 Precision: 0.9252336448598131 Recall: 0.99 F1 Score: 0.9565217391304348\n",
            "Case 14 Precision: 0.9393939393939394 Recall: 0.93 F1 Score: 0.9346733668341709\n",
            "Case 15 Precision: 0.8925233644859814 Recall: 0.955 F1 Score: 0.9227053140096618\n",
            "Case 16 Precision: 0.9393939393939394 Recall: 0.93 F1 Score: 0.9346733668341709\n",
            "Case 17 Precision: 0.9574468085106383 Recall: 0.9 F1 Score: 0.9278350515463918\n",
            "Case 18 Precision: 0.9353233830845771 Recall: 0.94 F1 Score: 0.9376558603491272\n",
            "Case 19 Precision: 0.9052132701421801 Recall: 0.955 F1 Score: 0.9294403892944039\n",
            "Case 20 Precision: 0.95 Recall: 0.95 F1 Score: 0.9500000000000001\n",
            "Case 21 Precision: 0.9 Recall: 0.945 F1 Score: 0.921951219512195\n",
            "Case 22 Precision: 0.94 Recall: 0.94 F1 Score: 0.94\n",
            "Case 23 Precision: 0.91005291005291 Recall: 0.86 F1 Score: 0.884318766066838\n",
            "Case 24 Precision: 0.9435897435897436 Recall: 0.92 F1 Score: 0.9316455696202531\n",
            "Case 25 Precision: 0.9211822660098522 Recall: 0.935 F1 Score: 0.9280397022332506\n",
            "Case 26 Precision: 0.9368932038834952 Recall: 0.965 F1 Score: 0.9507389162561576\n",
            "Case 27 Precision: 0.968421052631579 Recall: 0.92 F1 Score: 0.9435897435897437\n",
            "Case 28 Precision: 0.917098445595855 Recall: 0.885 F1 Score: 0.900763358778626\n",
            "Case 29 Precision: 0.97 Recall: 0.97 F1 Score: 0.97\n",
            "Case 30 Precision: 0.94 Recall: 0.94 F1 Score: 0.94\n"
          ]
        }
      ],
      "source": [
        "# Define dimension of the data\n",
        "dim = 10\n",
        "\n",
        "# Define the number of samples to generate\n",
        "target_num_samples = 200  # This is the number of positive samples in the testing set\n",
        "\n",
        "# Try 10 times\n",
        "for r in range(30):\n",
        "\n",
        "    # Initialize the dataset\n",
        "    Sn = []  # List to store negative samples\n",
        "    Sp = []  # List to store positive samples\n",
        "    num_n = 0  # Counter for negative samples\n",
        "    num_p = 0  # Counter for positive samples\n",
        "    true_positive = 0  # Counter for true positive samples\n",
        "    true_negative = 0  # Counter for true negative samples\n",
        "    false_positive = 0  # Counter for false positive samples\n",
        "    false_negative = 0  # Counter for false negative samples\n",
        "\n",
        "    # Generate samples until the target number is reached for both positive and negative samples\n",
        "    while num_p < target_num_samples * 2 or num_n < target_num_samples * 2:\n",
        "        # Generate a random vector within the range [-5, 5] with dimension (dim+1)\n",
        "        random_sample = np.random.uniform(-5, 5, (dim + 1))\n",
        "        # Set the last dimension to 0 temporarily\n",
        "        random_sample[dim] = 0\n",
        "        # Compute the sum of the vector components\n",
        "        sum_vector = np.sum(random_sample)\n",
        "        # If the sum is positive, append the sample to Sp\n",
        "        if sum_vector > 0:\n",
        "            if num_p < target_num_samples * 2:\n",
        "                random_sample[dim] = 1\n",
        "                Sp.append(random_sample)\n",
        "                num_p += 1\n",
        "        elif num_n < target_num_samples * 2:\n",
        "            random_sample[dim] = -1\n",
        "            Sn.append(random_sample)\n",
        "            num_n += 1\n",
        "\n",
        "    # Split the dataset into training (Sp, Sn) and testing (Tp, Tn)\n",
        "    # The last target_num_samples samples from Sn and Sp are used for testing.\n",
        "    Tp = Sp[target_num_samples:]\n",
        "    Tn = Sn[target_num_samples:]\n",
        "\n",
        "    # The first target_num_samples samples from Sn and Sp are used for training.\n",
        "    Sp = Sp[:target_num_samples]\n",
        "    Sn = Sn[:target_num_samples]\n",
        "\n",
        "    # Combine positive and negative samples to create the dataset\n",
        "    dataset = Sn + Sp\n",
        "\n",
        "    # Calculate the Gaussian distribution based on training data\n",
        "    mean_p, sd_p, mean_n, sd_n = binary_bc_training(dataset, dim)\n",
        "\n",
        "    # Combine positive and negative samples to create the testing dataset\n",
        "    testing_dataset = Tp + Tn\n",
        "\n",
        "    # Initialize counters for evaluation metrics\n",
        "    true_positive = 0\n",
        "    true_negative = 0\n",
        "    false_positive = 0\n",
        "    false_negative = 0\n",
        "\n",
        "    # Loop through the testing_dataset\n",
        "    for each in range(len(testing_dataset)):\n",
        "        # Make a prediction using the binary_bc_inferencing function with the testing sample\n",
        "        prediction = binary_bc_inferencing(mean_p, sd_p, mean_n, sd_n, testing_dataset[each][0:dim], dim, 0.5, 0.5)  # Prior probability = 0.5 for both classes\n",
        "\n",
        "        # Increment the appropriate counters based on whether the inference is true positive, true negative, false positive, or false negative\n",
        "        if testing_dataset[each][dim] == 1:\n",
        "            if prediction == 1:\n",
        "                true_positive += 1\n",
        "            else:\n",
        "                false_negative += 1\n",
        "        else:\n",
        "            if prediction == -1:\n",
        "                true_negative += 1\n",
        "            else:\n",
        "                false_positive += 1\n",
        "\n",
        "    # Calculate precision\n",
        "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
        "\n",
        "    # Calculate recall\n",
        "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    # Print the result\n",
        "    print(\"Case\",r+1,\"Precision:\", precision, \"Recall:\", recall, \"F1 Score:\", f1score)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LW8tQe8ataJ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}