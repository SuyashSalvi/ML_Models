{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title This code implements the training of the perceptron learning algorithm (PLA).\n",
        "def perceptron_training(w_vec, dataset):\n",
        "    epoch = 0\n",
        "    w_vectors = [] # List to store weight vectors at each epoch\n",
        "    missed = [] # List to store number of misclassifications at each epoch\n",
        "    #plotting_classification_result10(w_vector, 'Initial W') # Plot the classificaiton result with initial weight vector\n",
        "    # To-Do\n",
        "    a = misclassified(dataset, w_vec)\n",
        "    while True:\n",
        "        missed.append(a)\n",
        "        if a == 0:  # If no misclassifications, break the loop\n",
        "            break\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "        for sample in dataset:\n",
        "            y = (w_vec[0] + (sample[0] * w_vec[1]) + (sample[1] * w_vec[2]))\n",
        "            y = activation_fn(y)\n",
        "\n",
        "\n",
        "            if y != sample[2]:\n",
        "                #print ('Preupdate weights: ', w_vec)\n",
        "                #print ('Sample points', sample[1:])\n",
        "                w_vec[0] += sample[2]  # Update w0\n",
        "                w_vec[1] += sample[2] * sample[0]  # Update w1\n",
        "                w_vec[2] += sample[2] * sample[1]  # Update w2\n",
        "                #print ('Updated weights: ', w_vec)\n",
        "\n",
        "        a = misclassified(dataset, w_vec)\n",
        "        #print('Number of Misclassifications: ', a)\n",
        "\n",
        "        #plotting_classification_result10(Sp, Sn, w_vec, 'Epoch # ' + str(epoch))\n",
        "        w_vectors.append(w_vec.copy())\n",
        "\n",
        "    #print ('Final weights: ', w_vectors[-1])\n",
        "    return w_vectors, missed\n"
      ],
      "metadata": {
        "id": "ipL24KlXSk6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L5zBmp6XUDz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "# Activation function to determine the output based on input value\n",
        "def activation_fn(x):\n",
        "    if x >= 0:\n",
        "        y = 1 # Positive Sample Set\n",
        "    else:\n",
        "        y = -1 # Negative Sample Set\n",
        "    return y\n",
        "\n",
        "# Function to calculate the number of misclassifications in the dataset using current weight vector\n",
        "def misclassified(dataset, w_vector):\n",
        "    misclassifications = 0\n",
        "    #print (\"===Testing===\")\n",
        "    for sample in dataset: # The first two in samples are the x,y coordinates. The last one in sample is the label.\n",
        "        y = (w_vector[0]+(sample[0]*w_vector[1])+(sample[1]*w_vector[2]))\n",
        "        y = activation_fn(y)\n",
        "        if y != sample[2]:\n",
        "            misclassifications += 1\n",
        "    return misclassifications\n",
        "\n",
        "# Function to plot the classification result with the current weight vector\n",
        "def plotting_classification_result10(Sp, Sn, w_vector, title):\n",
        "    # Initilize the scale for the plot\n",
        "    scale=10 # Scale for the plot\n",
        "\n",
        "    # Collect the coordinates for the postive and negative samples (for the easy of ploting)\n",
        "    Sp_x = [] # List to store x-coordinates of positive samples\n",
        "    Sp_y = [] # List to store y-coordinates of positive samples\n",
        "    Sn_x = [] # List to store x-coordinates of negative samples\n",
        "    Sn_y = [] # List to store y-coordinates of negative samples\n",
        "\n",
        "    # Iterate through positive samples and append x, y coordinates to respective lists\n",
        "    for i in Sp:\n",
        "        Sp_x.append(i[0])\n",
        "        Sp_y.append(i[1])\n",
        "\n",
        "    # Iterate through negative samples and append x, y coordinates to respective lists\n",
        "    for i in Sn:\n",
        "        Sn_x.append(i[0])\n",
        "        Sn_y.append(i[1])\n",
        "\n",
        "    w0=w_vector[0]\n",
        "    w1=w_vector[1]\n",
        "    w2=w_vector[2]\n",
        "    if w1 != 0:\n",
        "      x1 = -(w0-w2*scale/2)/w1\n",
        "      x2 = -(w0+w2*scale/2)/w1\n",
        "      X = np.array([x1, x2])\n",
        "      Y = np.array([-scale/2, scale/2])\n",
        "    elif w2 != 0:\n",
        "      y1 = -(w0-w1*scale/2)/w2\n",
        "      y2 = -(w0+w1*scale/2)/w2\n",
        "      X = np.array([-scale/2, scale/2])\n",
        "      Y = np.array([y1, y2])\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "    blue = plt.scatter(Sn_x, Sn_y, c ='b', label='Sn : {} elements'.format(len(Sn_x)))\n",
        "    red = plt.scatter(Sp_x, Sp_y, c='r', marker = \"^\", label='Sp : {} elements'.format(len(Sp_x)))\n",
        "    line = ax.plot(X, Y, c = 'green', label='Perceptron Decision Boundary')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.ylim([-scale/2,scale/2])\n",
        "    plt.xlim([-scale/2,scale/2])\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot the graph on the number of misclassifications vs. the updates\n",
        "def plotting_misclassification_over_updates(w_history, missed):\n",
        "    n_updates = range(len(w_history)+1) # Create a range of updates for x-axis of plot\n",
        "    fig, ax = plt.subplots(figsize=(10,10)) # Create a plot figure\n",
        "    ax.plot(n_updates, missed+[0], c = 'green') # Plot number of misclassifications vs. updates\n",
        "    plt.ylabel('Number of Misclassifications') # Set y-axis label\n",
        "    plt.xlabel('Number of Updates') # Set x-axis label\n",
        "    plt.ylim(bottom=0) # Set lower limit of y-axis to 0\n",
        "    plt.xlim(left=0) # Set lower limit of x-axis to 0\n",
        "    plt.show() # Display the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Initializing the ground truth boundary of a dataset and creating a training and testing dataset for a perceptron classifier.\n",
        "\n",
        "# Initilize the true boundary, aka, ground truth\n",
        "w0 = 0\n",
        "w1 = 1\n",
        "w2 = 1\n",
        "true_w_vector = [w0, w1, w2]\n",
        "accuracy_list = []\n",
        "\n",
        "for r in range(10):\n",
        "  # Initilize the dataset\n",
        "  Sn = [] # List to store negative samples\n",
        "  Sp = [] # List to store positive samples\n",
        "  num_n = 0 # Counter for negative samples\n",
        "  num_p = 0 # Counter for positive samples\n",
        "\n",
        "  target_num_samples=20\n",
        "  while num_p < target_num_samples or num_n < target_num_samples:\n",
        "    i1 = np.random.uniform(-5, 5)\n",
        "    i2 = np.random.uniform(-5, 5)\n",
        "    if (1*w0)+(i1*w1)+(i2*w2) >= 0:\n",
        "      if num_p < target_num_samples:\n",
        "        Sp.append([i1] + [i2] + [1])\n",
        "        num_p +=1\n",
        "    elif num_n < target_num_samples:\n",
        "      Sn.append([i1] + [i2] + [-1])\n",
        "      num_n +=1\n",
        "\n",
        "  #plotting_classification_result10(Sp, Sn, true_w_vector, 'Ground Truth')\n",
        "\n",
        "  # Split the dataset in to training (Sp, Sn) and testing (Tp, Tn)\n",
        "  # The last 10 samples from Sn and Sp are used for testing.\n",
        "  Tp = Sp[-10:]\n",
        "  Tn = Sn[-10:]\n",
        "  #print(Tp, Tn)\n",
        "  # The first 10 or 6 samples from Sn and Sp are used for training.\n",
        "  Sp = Sp[:10]  # To-Do\n",
        "  Sn = Sn[:10]  # To-Do\n",
        "  #print(Sp, Sn)\n",
        "  # Combine positive and negative samples to create the dataset\n",
        "  dataset = Sn + Sp\n",
        "\n",
        "  # Initilize the weight\n",
        "  w0 = np.random.uniform(-1/4, 1/4)\n",
        "  w1 = np.random.uniform(-1, 1)\n",
        "  w2 = np.random.uniform(-1, 1)\n",
        "  w_vector = [w0, w1, w2]\n",
        "\n",
        "  #plotting_classification_result10(Sp, Sn, w_vector, 'Initial W')\n",
        "\n",
        "  a = misclassified(dataset, w_vector) # Get the number of misclassifications\n",
        "  #print ('Number of Misclassifications: ', a)\n",
        "\n",
        "  #print ('Initial weights: ' , w_vector)\n",
        "  w_history=[] # List to store weight history during training\n",
        "  w_history, missed = perceptron_training(w_vector, dataset) # Call perceptron_training function to get weight history and number of misclassifications\n",
        "\n",
        "  #plotting_classification_result10(Sp, Sn, w_history[-1], 'Final W')\n",
        "\n",
        "  # Perform classification on test data\n",
        "  #plotting_classification_result10(Tp, Tn, w_history[-1], 'Final W on test data')\n",
        "  a = misclassified(Tp + Tn, w_vector) # Get the number of misclassifications\n",
        "  print ('Number of Misclassifications: ', a)\n",
        "  print('Accuracy: ', 1 - a / (len(Tp)+len(Tn)))\n",
        "  accuracy_list.append(1 - a / (len(Tp)+len(Tn)))\n",
        "  #plotting_misclassification_over_epochs(w_history, missed)\n",
        "\n",
        "print(\"Avg accuracy:\",np.mean(accuracy_list))\n",
        "print(\"Std deviation:\",np.std(accuracy_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SyZdDqRXmm5",
        "outputId": "b0f4cbce-8de8-422c-9773-7f186f62e43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Misclassifications:  5\n",
            "Accuracy:  0.75\n",
            "Number of Misclassifications:  1\n",
            "Accuracy:  0.95\n",
            "Number of Misclassifications:  1\n",
            "Accuracy:  0.95\n",
            "Number of Misclassifications:  3\n",
            "Accuracy:  0.85\n",
            "Number of Misclassifications:  0\n",
            "Accuracy:  1.0\n",
            "Number of Misclassifications:  0\n",
            "Accuracy:  1.0\n",
            "Number of Misclassifications:  1\n",
            "Accuracy:  0.95\n",
            "Number of Misclassifications:  2\n",
            "Accuracy:  0.9\n",
            "Number of Misclassifications:  0\n",
            "Accuracy:  1.0\n",
            "Number of Misclassifications:  2\n",
            "Accuracy:  0.9\n",
            "Avg accuracy: 0.925\n",
            "Std deviation: 0.075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initializing the ground truth boundary of a dataset and creating a training and testing dataset for a perceptron classifier.\n",
        "\n",
        "# Initilize the true boundary, aka, ground truth\n",
        "w0 = 0\n",
        "w1 = 1\n",
        "w2 = 1\n",
        "true_w_vector = [w0, w1, w2]\n",
        "accuracy_list = []\n",
        "\n",
        "for r in range(10):\n",
        "  # Initilize the dataset\n",
        "  Sn = [] # List to store negative samples\n",
        "  Sp = [] # List to store positive samples\n",
        "  num_n = 0 # Counter for negative samples\n",
        "  num_p = 0 # Counter for positive samples\n",
        "\n",
        "  target_num_samples=20\n",
        "  while num_p < target_num_samples or num_n < target_num_samples:\n",
        "    i1 = np.random.uniform(-5, 5)\n",
        "    i2 = np.random.uniform(-5, 5)\n",
        "    if (1*w0)+(i1*w1)+(i2*w2) >= 0:\n",
        "      if num_p < target_num_samples:\n",
        "        Sp.append([i1] + [i2] + [1])\n",
        "        num_p +=1\n",
        "    elif num_n < target_num_samples:\n",
        "      Sn.append([i1] + [i2] + [-1])\n",
        "      num_n +=1\n",
        "\n",
        "  #plotting_classification_result10(Sp, Sn, true_w_vector, 'Ground Truth')\n",
        "\n",
        "  # Split the dataset in to training (Sp, Sn) and testing (Tp, Tn)\n",
        "  # The last 10 samples from Sn and Sp are used for testing.\n",
        "  Tp = Sp[-15:]\n",
        "  Tn = Sn[-15:]\n",
        "  #print(Tp, Tn)\n",
        "  # The first 10 or 6 samples from Sn and Sp are used for training.\n",
        "  Sp = Sp[:5]  # To-Do\n",
        "  Sn = Sn[:5]  # To-Do\n",
        "  #print(Sp, Sn)\n",
        "  # Combine positive and negative samples to create the dataset\n",
        "  dataset = Sn + Sp\n",
        "\n",
        "  # Initilize the weight\n",
        "  w0 = np.random.uniform(-1/4, 1/4)\n",
        "  w1 = np.random.uniform(-1, 1)\n",
        "  w2 = np.random.uniform(-1, 1)\n",
        "  w_vector = [w0, w1, w2]\n",
        "\n",
        "  #plotting_classification_result10(Sp, Sn, w_vector, 'Initial W')\n",
        "\n",
        "  a = misclassified(dataset, w_vector) # Get the number of misclassifications\n",
        "  #print ('Number of Misclassifications: ', a)\n",
        "\n",
        "  #print ('Initial weights: ' , w_vector)\n",
        "  w_history=[] # List to store weight history during training\n",
        "  w_history, missed = perceptron_training(w_vector, dataset) # Call perceptron_training function to get weight history and number of misclassifications\n",
        "\n",
        "  #plotting_classification_result10(Sp, Sn, w_history[-1], 'Final W')\n",
        "\n",
        "  # Perform classification on test data\n",
        "  #plotting_classification_result10(Tp, Tn, w_history[-1], 'Final W on test data')\n",
        "  a = misclassified(Tp + Tn, w_vector) # Get the number of misclassifications\n",
        "  print ('Number of Misclassifications: ', a)\n",
        "  print('Accuracy: ', 1 - a / (len(Tp)+len(Tn)))\n",
        "  accuracy_list.append(1 - a / (len(Tp)+len(Tn)))\n",
        "  #plotting_misclassification_over_epochs(w_history, missed)\n",
        "\n",
        "print(\"Avg accuracy:\",np.mean(accuracy_list))\n",
        "print(\"Std deviation:\",np.std(accuracy_list))\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGWTgHKlEIkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5af6cb4-6b19-4fa7-f971-049c3733b21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Misclassifications:  0\n",
            "Accuracy:  1.0\n",
            "Number of Misclassifications:  3\n",
            "Accuracy:  0.9\n",
            "Number of Misclassifications:  8\n",
            "Accuracy:  0.7333333333333334\n",
            "Number of Misclassifications:  4\n",
            "Accuracy:  0.8666666666666667\n",
            "Number of Misclassifications:  2\n",
            "Accuracy:  0.9333333333333333\n",
            "Number of Misclassifications:  5\n",
            "Accuracy:  0.8333333333333334\n",
            "Number of Misclassifications:  6\n",
            "Accuracy:  0.8\n",
            "Number of Misclassifications:  3\n",
            "Accuracy:  0.9\n",
            "Number of Misclassifications:  0\n",
            "Accuracy:  1.0\n",
            "Number of Misclassifications:  0\n",
            "Accuracy:  1.0\n",
            "Avg accuracy: 0.8966666666666667\n",
            "Std deviation: 0.08621678104251707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4fLzccGYrUG6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}