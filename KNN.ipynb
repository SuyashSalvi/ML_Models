{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ssMWrKhNakJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "8fINWmGc_wOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(point1, point2):\n",
        "    return np.linalg.norm(point1 - point2)\n",
        "\n",
        "def knn_inferencing(dataset, testing_point, dim):\n",
        "\n",
        "    min_length = dim * dim * 20\n",
        "    min_label = 0\n",
        "\n",
        "    x_test = testing_point[0:dim]\n",
        "\n",
        "    # Loop through the dataset to extract the vec_x and y parameters\n",
        "    for each in range(len(dataset)):\n",
        "        # Extract the feature values (x_train) and class label (last element)\n",
        "        x_train = dataset[each][0:dim]\n",
        "        y_train = dataset[each][dim]\n",
        "\n",
        "        # Calculate the distance between the training point and testing point\n",
        "        dist = distance(x_train, x_test)\n",
        "\n",
        "        # If the distance is smaller than the current minimum distance,\n",
        "        # update the minimum distance and minimum label accordingly\n",
        "        if dist < min_length:\n",
        "            min_length = dist\n",
        "            min_label = y_train\n",
        "\n",
        "    # Return the label of the nearest neighbor\n",
        "    return min_label\n"
      ],
      "metadata": {
        "id": "ktiwY7zk_umX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFsBMaYMoJqj",
        "outputId": "678e4780-3d6d-4a62-aea2-b3adef989531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case 1 Precision: 0.9302325581395349 Recall: 1.0 F1 Score: 0.963855421686747\n",
            "Case 2 Precision: 1.0 Recall: 1.0 F1 Score: 1.0\n",
            "Case 3 Precision: 0.9459459459459459 Recall: 0.875 F1 Score: 0.9090909090909091\n",
            "Case 4 Precision: 0.8863636363636364 Recall: 0.975 F1 Score: 0.9285714285714285\n",
            "Case 5 Precision: 1.0 Recall: 0.875 F1 Score: 0.9333333333333333\n",
            "Case 6 Precision: 1.0 Recall: 0.925 F1 Score: 0.961038961038961\n",
            "Case 7 Precision: 1.0 Recall: 0.975 F1 Score: 0.9873417721518987\n",
            "Case 8 Precision: 1.0 Recall: 1.0 F1 Score: 1.0\n",
            "Case 9 Precision: 1.0 Recall: 0.875 F1 Score: 0.9333333333333333\n",
            "Case 10 Precision: 1.0 Recall: 0.95 F1 Score: 0.9743589743589743\n",
            "Case 11 Precision: 0.95 Recall: 0.95 F1 Score: 0.9500000000000001\n",
            "Case 12 Precision: 0.975 Recall: 0.975 F1 Score: 0.975\n",
            "Case 13 Precision: 1.0 Recall: 0.85 F1 Score: 0.9189189189189189\n",
            "Case 14 Precision: 0.95 Recall: 0.95 F1 Score: 0.9500000000000001\n",
            "Case 15 Precision: 0.975 Recall: 0.975 F1 Score: 0.975\n",
            "Case 16 Precision: 0.95 Recall: 0.95 F1 Score: 0.9500000000000001\n",
            "Case 17 Precision: 0.9743589743589743 Recall: 0.95 F1 Score: 0.9620253164556962\n",
            "Case 18 Precision: 0.9743589743589743 Recall: 0.95 F1 Score: 0.9620253164556962\n",
            "Case 19 Precision: 0.8837209302325582 Recall: 0.95 F1 Score: 0.9156626506024096\n",
            "Case 20 Precision: 0.8837209302325582 Recall: 0.95 F1 Score: 0.9156626506024096\n",
            "Case 21 Precision: 0.972972972972973 Recall: 0.9 F1 Score: 0.935064935064935\n",
            "Case 22 Precision: 0.9512195121951219 Recall: 0.975 F1 Score: 0.9629629629629629\n",
            "Case 23 Precision: 0.9512195121951219 Recall: 0.975 F1 Score: 0.9629629629629629\n",
            "Case 24 Precision: 0.9473684210526315 Recall: 0.9 F1 Score: 0.9230769230769231\n",
            "Case 25 Precision: 1.0 Recall: 0.95 F1 Score: 0.9743589743589743\n",
            "Case 26 Precision: 0.9523809523809523 Recall: 1.0 F1 Score: 0.975609756097561\n",
            "Case 27 Precision: 0.9743589743589743 Recall: 0.95 F1 Score: 0.9620253164556962\n",
            "Case 28 Precision: 0.9512195121951219 Recall: 0.975 F1 Score: 0.9629629629629629\n",
            "Case 29 Precision: 0.975 Recall: 0.975 F1 Score: 0.975\n",
            "Case 30 Precision: 0.9285714285714286 Recall: 0.975 F1 Score: 0.951219512195122\n"
          ]
        }
      ],
      "source": [
        "# Define dimension of the data\n",
        "dim = 2\n",
        "\n",
        "# Define the number of samples to generate\n",
        "target_num_samples = 40  # This is the number of positive samples in the testing set\n",
        "\n",
        "# Try 10 times\n",
        "for r in range(30):\n",
        "\n",
        "    # Initialize the dataset\n",
        "    Sn = []  # List to store negative samples\n",
        "    Sp = []  # List to store positive samples\n",
        "    num_n = 0  # Counter for negative samples\n",
        "    num_p = 0  # Counter for positive samples\n",
        "    true_positive = 0  # Counter for true positive samples\n",
        "    true_negative = 0  # Counter for true negative samples\n",
        "    false_positive = 0  # Counter for false positive samples\n",
        "    false_negative = 0  # Counter for false negative samples\n",
        "\n",
        "    # Generate samples until the target number is reached for both positive and negative samples\n",
        "    while num_p < target_num_samples * 2 or num_n < target_num_samples * 2:\n",
        "        # Generate a random vector within the range [-5, 5] with dimension (dim+1)\n",
        "        random_sample = np.random.uniform(-5, 5, (dim + 1))\n",
        "        # Set the last dimension to 0 temporarily\n",
        "        random_sample[dim] = 0\n",
        "        # Compute the sum of the vector components\n",
        "        sum_vector = np.sum(random_sample)\n",
        "        # If the sum is positive, append the sample to Sp\n",
        "        if sum_vector > 0:\n",
        "            if num_p < target_num_samples * 2:\n",
        "                random_sample[dim] = 1\n",
        "                Sp.append(random_sample)\n",
        "                num_p += 1\n",
        "        elif num_n < target_num_samples * 2:\n",
        "            random_sample[dim] = -1\n",
        "            Sn.append(random_sample)\n",
        "            num_n += 1\n",
        "\n",
        "    # Split the dataset into training (Sp, Sn) and testing (Tp, Tn)\n",
        "    # The last target_num_samples samples from Sn and Sp are used for testing.\n",
        "    Tp = Sp[target_num_samples:]\n",
        "    Tn = Sn[target_num_samples:]\n",
        "\n",
        "    # The first target_num_samples samples from Sn and Sp are used for training.\n",
        "    Sp = Sp[:target_num_samples]\n",
        "    Sn = Sn[:target_num_samples]\n",
        "\n",
        "    # Combine positive and negative samples to create the dataset\n",
        "    dataset = Sn + Sp\n",
        "\n",
        "    # Combine positive and negative samples to create the testing dataset\n",
        "    testing_dataset = Tp + Tn\n",
        "\n",
        "    # Loop through the testing_dataset\n",
        "    for each in range(len(testing_dataset)):\n",
        "        # Make a prediction using the knn_inferencing function with the training dataset and the testing sample\n",
        "        prediction = knn_inferencing(dataset, testing_dataset[each], dim)\n",
        "\n",
        "        # Increment the appropriate counters based on whether the inference is true positive, true negative, false positive, or false negative\n",
        "        if testing_dataset[each][dim] == 1:\n",
        "            if prediction == 1:\n",
        "                true_positive += 1\n",
        "            else:\n",
        "                false_negative += 1\n",
        "        else:\n",
        "            if prediction == -1:\n",
        "                true_negative += 1\n",
        "            else:\n",
        "                false_positive += 1\n",
        "\n",
        "    # Calculate precision\n",
        "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
        "\n",
        "    # Calculate recall\n",
        "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    # Print the result\n",
        "    print(\"Case\",r+1,\"Precision:\", precision, \"Recall:\", recall, \"F1 Score:\", f1score)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dimension of the data\n",
        "dim = 10\n",
        "\n",
        "# Define the number of samples to generate\n",
        "target_num_samples = 200  # This is the number of positive samples in the testing set\n",
        "\n",
        "# Try 10 times\n",
        "for r in range(30):\n",
        "\n",
        "    # Initialize the dataset\n",
        "    Sn = []  # List to store negative samples\n",
        "    Sp = []  # List to store positive samples\n",
        "    num_n = 0  # Counter for negative samples\n",
        "    num_p = 0  # Counter for positive samples\n",
        "    true_positive = 0  # Counter for true positive samples\n",
        "    true_negative = 0  # Counter for true negative samples\n",
        "    false_positive = 0  # Counter for false positive samples\n",
        "    false_negative = 0  # Counter for false negative samples\n",
        "\n",
        "    # Generate samples until the target number is reached for both positive and negative samples\n",
        "    while num_p < target_num_samples * 2 or num_n < target_num_samples * 2:\n",
        "        # Generate a random vector within the range [-5, 5] with dimension (dim+1)\n",
        "        random_sample = np.random.uniform(-5, 5, (dim + 1))\n",
        "        # Set the last dimension to 0 temporarily\n",
        "        random_sample[dim] = 0\n",
        "        # Compute the sum of the vector components\n",
        "        sum_vector = np.sum(random_sample)\n",
        "        # If the sum is positive, append the sample to Sp\n",
        "        if sum_vector > 0:\n",
        "            if num_p < target_num_samples * 2:\n",
        "                random_sample[dim] = 1\n",
        "                Sp.append(random_sample)\n",
        "                num_p += 1\n",
        "        elif num_n < target_num_samples * 2:\n",
        "            random_sample[dim] = -1\n",
        "            Sn.append(random_sample)\n",
        "            num_n += 1\n",
        "\n",
        "    # Split the dataset into training (Sp, Sn) and testing (Tp, Tn)\n",
        "    # The last target_num_samples samples from Sn and Sp are used for testing.\n",
        "    Tp = Sp[target_num_samples:]\n",
        "    Tn = Sn[target_num_samples:]\n",
        "\n",
        "    # The first target_num_samples samples from Sn and Sp are used for training.\n",
        "    Sp = Sp[:target_num_samples]\n",
        "    Sn = Sn[:target_num_samples]\n",
        "\n",
        "    # Combine positive and negative samples to create the dataset\n",
        "    dataset = Sn + Sp\n",
        "\n",
        "    # Combine positive and negative samples to create the testing dataset\n",
        "    testing_dataset = Tp + Tn\n",
        "\n",
        "    # Loop through the testing_dataset\n",
        "    for each in range(len(testing_dataset)):\n",
        "        # Make a prediction using the knn_inferencing function with the training dataset and the testing sample\n",
        "        prediction = knn_inferencing(dataset, testing_dataset[each], dim)\n",
        "\n",
        "        # Increment the appropriate counters based on whether the inference is true positive, true negative, false positive, or false negative\n",
        "        if testing_dataset[each][dim] == 1:\n",
        "            if prediction == 1:\n",
        "                true_positive += 1\n",
        "            else:\n",
        "                false_negative += 1\n",
        "        else:\n",
        "            if prediction == -1:\n",
        "                true_negative += 1\n",
        "            else:\n",
        "                false_positive += 1\n",
        "\n",
        "    # Calculate precision\n",
        "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
        "\n",
        "    # Calculate recall\n",
        "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    # Print the result\n",
        "    print(\"Case\",r+1,\"Precision:\", precision, \"Recall:\", recall, \"F1 Score:\", f1score)"
      ],
      "metadata": {
        "id": "bFPK7G5csWI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee67d7ee-76af-4ad3-ca11-498d375d3c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case 1 Precision: 0.7868020304568528 Recall: 0.775 F1 Score: 0.7808564231738037\n",
            "Case 2 Precision: 0.7801047120418848 Recall: 0.745 F1 Score: 0.7621483375959079\n",
            "Case 3 Precision: 0.8090452261306532 Recall: 0.805 F1 Score: 0.8070175438596492\n",
            "Case 4 Precision: 0.7740384615384616 Recall: 0.805 F1 Score: 0.7892156862745099\n",
            "Case 5 Precision: 0.8134715025906736 Recall: 0.785 F1 Score: 0.7989821882951654\n",
            "Case 6 Precision: 0.7537688442211056 Recall: 0.75 F1 Score: 0.7518796992481204\n",
            "Case 7 Precision: 0.7511961722488039 Recall: 0.785 F1 Score: 0.7677261613691931\n",
            "Case 8 Precision: 0.8256410256410256 Recall: 0.805 F1 Score: 0.8151898734177216\n",
            "Case 9 Precision: 0.7860696517412935 Recall: 0.79 F1 Score: 0.7880299251870324\n",
            "Case 10 Precision: 0.801980198019802 Recall: 0.81 F1 Score: 0.8059701492537314\n",
            "Case 11 Precision: 0.8324324324324325 Recall: 0.77 F1 Score: 0.8000000000000002\n",
            "Case 12 Precision: 0.805 Recall: 0.805 F1 Score: 0.805\n",
            "Case 13 Precision: 0.8256410256410256 Recall: 0.805 F1 Score: 0.8151898734177216\n",
            "Case 14 Precision: 0.7912621359223301 Recall: 0.815 F1 Score: 0.8029556650246306\n",
            "Case 15 Precision: 0.8082901554404145 Recall: 0.78 F1 Score: 0.7938931297709924\n",
            "Case 16 Precision: 0.8256410256410256 Recall: 0.805 F1 Score: 0.8151898734177216\n",
            "Case 17 Precision: 0.782608695652174 Recall: 0.81 F1 Score: 0.7960687960687962\n",
            "Case 18 Precision: 0.84 Recall: 0.84 F1 Score: 0.8399999999999999\n",
            "Case 19 Precision: 0.7733990147783252 Recall: 0.785 F1 Score: 0.7791563275434242\n",
            "Case 20 Precision: 0.7442922374429224 Recall: 0.815 F1 Score: 0.7780429594272076\n",
            "Case 21 Precision: 0.8267326732673267 Recall: 0.835 F1 Score: 0.8308457711442786\n",
            "Case 22 Precision: 0.7832512315270936 Recall: 0.795 F1 Score: 0.7890818858560794\n",
            "Case 23 Precision: 0.7513227513227513 Recall: 0.71 F1 Score: 0.7300771208226221\n",
            "Case 24 Precision: 0.8071065989847716 Recall: 0.795 F1 Score: 0.801007556675063\n",
            "Case 25 Precision: 0.8080808080808081 Recall: 0.8 F1 Score: 0.8040201005025126\n",
            "Case 26 Precision: 0.806282722513089 Recall: 0.77 F1 Score: 0.7877237851662405\n",
            "Case 27 Precision: 0.806282722513089 Recall: 0.77 F1 Score: 0.7877237851662405\n",
            "Case 28 Precision: 0.8307692307692308 Recall: 0.81 F1 Score: 0.820253164556962\n",
            "Case 29 Precision: 0.7598039215686274 Recall: 0.775 F1 Score: 0.7673267326732675\n",
            "Case 30 Precision: 0.7616822429906542 Recall: 0.815 F1 Score: 0.78743961352657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D62YHc_-ddPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}